#!/usr/bin/env python3
# make_supportparser_data.py
# Generate synthetic customer-support parsing data with GPT-4o and save JSONL files.

import argparse
import json
import os
import random
import re
import time
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple

from pydantic import BaseModel, ValidationError
from dotenv import load_dotenv

# ---- OpenAI (new SDK) ----
# pip install openai python-dotenv pydantic
from openai import OpenAI
from openai._exceptions import RateLimitError, APIStatusError
load_dotenv()
# ---------------------------
# Schema for gold labels
# ---------------------------

class SupportSchema(BaseModel):
    intent: str  # damaged_item|return_request|cancel_order|exchange_request|missing_item|billing_issue
    order_id: Optional[str] = None
    item_name: Optional[str] = None
    days_since_delivery: Optional[int] = None
    is_hygiene_item: Optional[bool] = None
    requested_action: Optional[str] = None  # replacement|refund|cancel|exchange|null


SYSTEM_HEADER = (
    "You are a data generator for a dataset that maps messy customer messages to strict JSON.\n"
    "The data you are generating corresponds to customer complaints received by support team of an e-commerce platform.\n"
    "Just imagine there is a customer complaint (called message) and now you need to parse it into a structured JSON record(called gold) containing fields that you will find mentioned below.\n"
    "You must generate both message and gold. Also, ensure to keep a great variety of messages because we will be training a model on this data generated by you\n"
    "For each example, you MUST invoke the provided tool to submit a structured record.\n"
    "Each tool call should contain:\n"
    "  message: string (the customer's free-form message)\n"
    "  gold:    JSON object with keys {intent, order_id, item_name, days_since_delivery, is_hygiene_item, requested_action}\n"
    "Rules:\n"
    "  - The message must be realistic and varied (typos, emojis, lowercase, run-on text, code-mixing allowed).\n"
    "  - If something is unknown, set the gold field to null. Do NOT invent.\n"
    "  - intents ∈ {damaged_item, return_request, cancel_order, exchange_request, missing_item, billing_issue}.\n"
    "  - requested_action usually:\n"
    "       damaged_item → replacement, missing_item → replacement,\n"
    "       return_request → refund, exchange_request → exchange,\n"
    "       cancel_order → cancel, billing_issue → null (or 'refund' if clearly double charge).\n"
    "  - days_since_delivery is an integer number of days if the message implies delivery timing (yesterday=1, today=0, etc.). Use null for pre-delivery/cancel cases.\n"
    "  - is_hygiene_item is true for items like facewash, sunscreen, toothbrush, supplements, cosmetics; otherwise false.\n"
    "  - Keep order_id realistic like '8341' or 'ORD-5521'; may be missing.\n"
    "  - Do NOT output plain text; only submit tool calls with structured arguments."
)

# Few-shot guidance to push realism & label consistency
FEWSHOT = [
    {
        "message": "hey, my water bottle came yesterday but cap cracked; order 8831, can i swap pls 🙏",
        "gold": {
            "intent": "damaged_item",
            "order_id": "8831",
            "item_name": "water bottle",
            "days_since_delivery": 1,
            "is_hygiene_item": False,
            "requested_action": "replacement"
        }
    },
    {
        "message": "placed an order like 20 mins ago… i found it cheaper, wanna cancel before shipping. id: ORD-5521",
        "gold": {
            "intent": "cancel_order",
            "order_id": "ORD-5521",
            "item_name": None,
            "days_since_delivery": None,
            "is_hygiene_item": None,
            "requested_action": "cancel"
        }
    },
    {
        "message": "hi, i bought facewash 5 days back, unopened seal intact; want to return and get refund",
        "gold": {
            "intent": "return_request",
            "order_id": None,
            "item_name": "facewash",
            "days_since_delivery": 5,
            "is_hygiene_item": True,
            "requested_action": "refund"
        }
    },
    {
        "message": "package delivered 3d ago but the protein shaker is missing… odr 4429",
        "gold": {
            "intent": "missing_item",
            "order_id": "4429",
            "item_name": "protein shaker",
            "days_since_delivery": 3,
            "is_hygiene_item": False,
            "requested_action": "replacement"
        }
    },
    {
        "message": "weird—i see 2 charges for same purchase on my order history page",
        "gold": {
            "intent": "billing_issue",
            "order_id": None,
            "item_name": None,
            "days_since_delivery": None,
            "is_hygiene_item": None,
            "requested_action": None
        }
    },
    {
        "message": "pls exchange the running shoes i got yesterday; need a different size. order #7742",
        "gold": {
            "intent": "exchange_request",
            "order_id": "7742",
            "item_name": "running shoes",
            "days_since_delivery": 1,
            "is_hygiene_item": False,
            "requested_action": "exchange"
        }
    }
]

# ---------------------------
# Helpers
# ---------------------------

def backoff_sleep(attempt: int):
    time.sleep(min(2 ** attempt, 20))

def parse_ndjson(s: str) -> List[Dict]:
    lines = [ln.strip() for ln in s.splitlines() if ln.strip()]
    objs = []
    for ln in lines:
        # extract first {...} block per line if model adds extra text
        m = re.search(r"\{.*\}", ln, flags=re.S)
        if not m:
            continue
        try:
            obj = json.loads(m.group(0))
            objs.append(obj)
        except json.JSONDecodeError:
            # try to fix trailing commas or smart quotes quickly
            ln2 = ln.replace("“","\"").replace("”","\"").replace("’","'")
            ln2 = re.sub(r",\s*}", "}", ln2)
            ln2 = re.sub(r",\s*]", "]", ln2)
            try:
                obj = json.loads(ln2)
                objs.append(obj)
            except Exception:
                pass
    return objs

def validate_record(obj: Dict) -> Optional[Tuple[str, Dict]]:
    """
    Expect: {"message": <str>, "gold": <dict>}
    Validate gold with SupportSchema. Return (message, gold_dict) if ok.
    """
    if not isinstance(obj, dict):
        return None
    msg = obj.get("message")
    gold = obj.get("gold")
    if not isinstance(msg, str) or not isinstance(gold, dict):
        return None
    try:
        parsed = SupportSchema.model_validate(gold).model_dump()
        return msg, parsed
    except ValidationError:
        return None

def fewshot_block(n: int) -> str:
    """Return n few-shot examples as NDJSON text."""
    n = min(n, len(FEWSHOT))
    return "\n".join(json.dumps(FEWSHOT[i], ensure_ascii=False) for i in range(n))

def build_user_prompt(num_examples: int) -> str:
    return (
        f"Generate exactly {num_examples} diverse examples. "
        f"For each one, INVOKE the tool to submit the example. "
        f"Do not emit free-form text. "
        f"Vary intents, items, days, presence/absence of order_id, and realism. "
        f"Include some hygiene items (facewash, sunscreen, toothbrush, supplements). "
        f"Use concise messages (1–2 sentences)."
    )

# Tool schema for structured examples
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "record_example",
            "description": "Record one synthetic support example",
            "parameters": {
                "type": "object",
                "properties": {
                    "message": {"type": "string"},
                    "gold": {
                        "type": "object",
                        "properties": {
                            "intent": {"type": "string", "enum": [
                                "damaged_item", "return_request", "cancel_order", "exchange_request", "missing_item", "billing_issue"
                            ]},
                            "order_id": {"type": ["string", "null"]},
                            "item_name": {"type": ["string", "null"]},
                            "days_since_delivery": {"type": ["integer", "null"]},
                            "is_hygiene_item": {"type": ["boolean", "null"]},
                            "requested_action": {"type": ["string", "null"]}
                        },
                        "required": ["intent"],
                        "additionalProperties": False
                    }
                },
                "required": ["message", "gold"],
                "additionalProperties": False
            }
        }
    }
]

# ---------------------------
# OpenAI call
# ---------------------------

def call_gpt(client: OpenAI, model: str, num_examples: int, shots: int, temperature: float):
    """Ask GPT to produce structured tool calls with examples."""
    sys_content = SYSTEM_HEADER
    if shots > 0:
        sys_content += "\nHere are correct NDJSON examples (for guidance only):\n" + fewshot_block(shots) # NDJSON stands for Newline-Delimited JSON. It’s a format where each line is an independent JSON object. 
    sys_msg = {"role": "system", "content": sys_content}
    msgs = [sys_msg]

    msgs.append({"role": "user", "content": build_user_prompt(num_examples)})

    resp = client.chat.completions.create(
        model=model,
        messages=msgs,
        temperature=temperature,
        tools=TOOLS,
        tool_choice={"type": "function", "function": {"name": "record_example"}}
    )
    return resp

def extract_records_from_tool_calls(resp) -> List[Dict]:
    """Extract list of {message, gold} dicts from tool calls in the response."""
    records: List[Dict] = []
    if not resp.choices:
        return records
    msg = resp.choices[0].message
    tool_calls = getattr(msg, "tool_calls", None) or []
    for call in tool_calls:
        try:
            if getattr(call, "function", None) and getattr(call.function, "name", "") == "record_example":
                args_str = getattr(call.function, "arguments", "{}")
                args = json.loads(args_str)
                message = args.get("message")
                gold = args.get("gold")
                if isinstance(message, str) and isinstance(gold, dict):
                    records.append({"message": message, "gold": gold})
        except Exception:
            # Skip malformed tool call
            continue
    return records

def generate_dataset(
    total: int,
    batch: int,
    shots: int,
    model: str,
    temperature: float,
    max_retries: int = 4
) -> List[Tuple[str, Dict]]:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not found in environment. Put it in your .env")
    client = OpenAI(api_key=api_key)

    results: List[Tuple[str, Dict]] = []
    remaining = total
    attempt = 0

    while remaining > 0:
        n = min(batch, remaining)
        try:
            resp = call_gpt(client, model, n, shots, temperature)
            # Primary path: parse tool calls
            records = extract_records_from_tool_calls(resp)
            for rec in records:
                ok = validate_record(rec)
                if ok:
                    results.append(ok)
            # Fallback: sometimes models still return text; parse it if present
            content = getattr(resp.choices[0].message, "content", None)
            if content:
                objs = parse_ndjson(content)
                for obj in objs:
                    ok = validate_record(obj)
                    if ok:
                        results.append(ok)
            remaining = total - len(results)
            attempt = 0  # reset after success
        except (RateLimitError, APIStatusError) as e:
            attempt += 1
            if attempt > max_retries:
                raise
            backoff_sleep(attempt)

    return results

# ---------------------------
# Save formats
# ---------------------------

def save_raw_ndjson(pairs: List[Tuple[str, Dict]], path: Path):
    with path.open("w", encoding="utf-8") as f:
        for msg, gold in pairs:
            f.write(json.dumps({"message": msg, "gold": gold}, ensure_ascii=False) + "\n")

def to_trl_example(message: str, gold: Dict) -> Dict:
    """
    Format a single example as a single 'text' field for TRL/PEFT SFT.
    We inline a minimal system prompt and put ONLY the gold JSON as assistant content.
    """
    system_hdr = (
        "You are a parser. Output ONLY one JSON object with keys: "
        "intent, order_id, item_name, days_since_delivery, is_hygiene_item, requested_action. "
        "No extra text. If a field is unknown, use null."
    )
    prompt = (
        f"<|system|>\n{system_hdr}\n"
        f"<|user|>\n{message}\n"
        f"<|assistant|>\n{json.dumps(gold, ensure_ascii=False)}"
    )
    return {"text": prompt}

def save_trl_jsonl(pairs: List[Tuple[str, Dict]], path: Path):
    with path.open("w", encoding="utf-8") as f:
        for msg, gold in pairs:
            f.write(json.dumps(to_trl_example(msg, gold), ensure_ascii=False) + "\n")

# ---------------------------
# CLI
# ---------------------------

def main():
    parser = argparse.ArgumentParser(description="Generate synthetic SupportParser data with GPT-4o.")
    parser.add_argument("--total", type=int, default=700, help="Total examples to generate.")
    parser.add_argument("--train", type=int, default=500, help="How many to put in train.jsonl (rest go to val.jsonl).")
    parser.add_argument("--batch", type=int, default=25, help="How many examples to ask per API call.")
    parser.add_argument("--shots", type=int, default=3, help="Few-shot examples to include (0–6).")
    parser.add_argument("--model", type=str, default="gpt-4o", help="OpenAI model (e.g., gpt-4o, gpt-4o-mini).")
    parser.add_argument("--temperature", type=float, default=0.6, help="Sampling temperature.")
    parser.add_argument("--outdir", type=str, default="data", help="Output dir.")
    parser.add_argument("--prefix", type=str, default="supportparser", help="File prefix.")
    args = parser.parse_args()

    if args.train > args.total:
        raise ValueError("--train cannot exceed --total")

    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    print(f"Generating {args.total} examples via {args.model} (batch={args.batch}, shots={args.shots})…")
    pairs = generate_dataset(
        total=args.total,
        batch=args.batch,
        shots=args.shots,
        model=args.model,
        temperature=args.temperature
    )
    print(f"Got {len(pairs)} validated examples.")

    # Shuffle and split
    random.shuffle(pairs)
    train_pairs = pairs[:args.train]
    val_pairs = pairs[args.train:]

    # Save raw NDJSON : Easy to eyeball messages and gold labels, fix errors, dedupe, or curate a gold set.
    # can reformat this same source later for other trainers, prompt-only baselines, or different schemas—without re-calling the LLM
    # many eval scripts want clean (input, gold) pairs; using the raw file avoids parsing the SFT formatting.
    raw_train = outdir / f"{args.prefix}_raw_train.jsonl"
    raw_val   = outdir / f"{args.prefix}_raw_val.jsonl"
    save_raw_ndjson(train_pairs, raw_train)
    save_raw_ndjson(val_pairs, raw_val)

    # Save TRL-ready JSONL
    # Plug-and-play with TRL/SFT: the trainer expects one “flattened conversation” per example.
    trl_train = outdir / "train.jsonl"
    trl_val   = outdir / "val.jsonl"
    save_trl_jsonl(train_pairs, trl_train)
    save_trl_jsonl(val_pairs, trl_val)

    print("Wrote:")
    print(f"  Raw: {raw_train}  ({len(train_pairs)})")
    print(f"       {raw_val}    ({len(val_pairs)})")
    print(f"  TRL: {trl_train}  ({len(train_pairs)})")
    print(f"       {trl_val}    ({len(val_pairs)})")
    print("\nNext: use train.jsonl / val.jsonl in your Colab fine-tune script.")

if __name__ == "__main__":
    main()
